# @package _global_
defaults:
    - override /data: mocap/trainX_testY
    - override /model: diffusion/diffusion_pl
    - override /endecoder: diffusion/v1_bodypose_hml3darcticgrab_angley
    - override /optimizer: adamw_1e-4
    - override /train_datasets:
          - amass/amass_aug
          - arctic/body
          - grab/body
    - override /test_datasets:
          - amass/amass_test
    - override /callbacks:
          - simple_ckpt_saver/every50e_top100
          - prog_bar/prog_reporter_every0.1
          - train_speed_timer/base
          - lr_monitor/pl
    - override /network: diffusion/bodypose_angley_transformer

exp_name_base: diffusion
exp_name_var: "bodypose"
exp_name: ${exp_name_base}${exp_name_var}
data_name: amassmix

pipeline:
    _target_: coda.model.diff.pipeline.text_pipeline.Pipeline
    args_denoiser3d:
        _target_: coda.network.transformer.rope_transformer.NetworkEncoderRoPE
        max_len: 300
        output_dim: 140
        objtraj_dim: 0
        beta_dim: 0
        skeleton_dim: 0
        clip_dim: 0

    args:
        endecoder_opt:
            _target_: coda.model.diff.utils.endecoder.BodyPoseEnDecoder
            is_angleay: True
            stats_name: BODYPOSE_AMASS_ANGLEY

        guidance_scale: 1.0
        num_inference_steps: 50
        scheduler_opt_train: # Always DDPM
            beta_schedule: squaredcos_cap_v2 # cosine instead of linear
            prediction_type: sample
            clip_sample: False
            timestep_spacing: "linspace"
            num_train_timesteps: 1000
        scheduler_opt_sample:
            _target_: diffusers.schedulers.DDIMScheduler 
            beta_schedule: squaredcos_cap_v2 # cosine instead of linear
            prediction_type: sample
            clip_sample: False
            timestep_spacing: "linspace"
            num_train_timesteps: 1000
    args_clip:
        _target_: coda.network.clip.clip_text_vision_base_patch32.CLIPLatentEncoder


data:
    loader_opts:
        train:
            batch_size: 256
            num_workers: 2
        val: # during training use this to evaluate
            batch_size: 32
            num_workers: 2
        test:
            batch_size: 32
            num_workers: 2

pl_trainer:
    precision: 16-mixed
    # precision: 32
    log_every_n_steps: 50
    gradient_clip_val: 0.5
    max_epochs: 2000
    check_val_every_n_epoch: 100
    devices: 1

logger:
    _target_: pytorch_lightning.loggers.WandbLogger
    save_dir: ${output_dir} # /save_dir/name/version/sub_dir
    name: ${exp_name_base}${exp_name_var}
    project: diffusion_bodypose